import torch
import torch.nn as nn

class LSTMWithTabular(nn.Module):
    def __init__(self, input_dim_seq, hidden_dim, num_layers, input_dim_static, output_dim):
        super(LSTMWithTabular, self).__init__()

        # ğŸ”¹ LSTM pour la sÃ©quence temporelle
        self.lstm = nn.LSTM(input_dim_seq, hidden_dim, num_layers, batch_first=True, dropout=0.2)
        
        # ğŸ”¹ MLP pour les features tabulaires
        self.fc_static = nn.Sequential(
            nn.Linear(input_dim_static, 32),
            nn.ReLU(),
            nn.Dropout(0.2)
        )

        # ğŸ”¹ Fusion et prÃ©diction finale
        self.fc_final = nn.Sequential(
            nn.Linear(hidden_dim + 32, 64),
            nn.ReLU(),
            nn.Linear(64, output_dim)
        )

    def forward(self, X_seq, X_static):
        # ğŸ”¹ LSTM : rÃ©cupÃ©rer la derniÃ¨re sortie cachÃ©e
        lstm_out, _ = self.lstm(X_seq)
        lstm_out = lstm_out[:, -1, :]  # DerniÃ¨re sortie de la sÃ©quence
        
        # ğŸ”¹ MLP pour les features tabulaires
        static_out = self.fc_static(X_static)

        # ğŸ”¹ Fusion et prÃ©diction
        combined = torch.cat((lstm_out, static_out), dim=1)
        output = self.fc_final(combined)
        
        return output
