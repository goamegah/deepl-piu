import torch
import pandas as pd
import numpy as np
import joblib
import argparse
from piu.models.mlp import MultiClassNN  # ‚úÖ V√©rifie que ton mod√®le est bien import√©
from piu.models.hwn import HighwayNet  # ‚úÖ V√©rifie que ton mod√®le est bien import√©
from piu.definitions import * # ‚úÖ V√©rifie les chemins

CHECKPOINT_DIR = f"{CHECKPOINT_PATH}/mlp-fs-correlation_threshold-balance-class_weight"  # ‚úÖ V√©rifie le chemin du mod√®le
MODEL_PATH = f"{CHECKPOINT_DIR}/best_model.pth"  # ‚úÖ V√©rifie le chemin du mod√®le
PREPROCESSOR_PATH = f"{CHECKPOINT_DIR}/preprocessor.pkl"  # ‚úÖ V√©rifie le chemin du pr√©processeur
DATA_PATH = f"{TEST_DATA_PATH}"  # ‚úÖ V√©rifie le chemin des donn√©es de test

def load_model(model_path, input_size, hidden_size, num_classes, num_layers, type="mlp"):
    """Charge un mod√®le PyTorch entra√Æn√©."""
    if type == "mlp":
        model = MultiClassNN(input_size, hidden_size, num_classes)
    elif type == "hwn":
        model = HighwayNet(input_size, hidden_size, num_classes, num_layers)
    model.load_state_dict(torch.load(model_path, weights_only=True, map_location=torch.device('cpu')))
    model.eval()
    return model

def align_columns(df, preprocessor):
    """Aligne les colonnes du test set avec celles utilis√©es pendant l'entra√Ænement."""
    train_columns = preprocessor.train_features  # ‚úÖ Sauvegard√© √† l'entra√Ænement
    missing_cols = set(train_columns) - set(df.columns)
    extra_cols = set(df.columns) - set(train_columns)

    # Ajouter les colonnes manquantes (avec valeurs nulles ou 0)
    for col in missing_cols:
        df[col] = 0 if col in preprocessor.cat_features else np.nan

    # Supprimer les colonnes en trop
    df = df.drop(columns=extra_cols, errors='ignore')

    # R√©ordonner les colonnes pour correspondre au training
    df = df[train_columns]

    return df

def predict(model, X):
    """Effectue une pr√©diction sur les donn√©es transform√©es."""
    with torch.no_grad():
        outputs = model(X)
        probabilities = torch.softmax(outputs, dim=1)
        predictions = torch.argmax(probabilities, dim=1)
    return predictions.numpy(), probabilities.numpy()

def batch_predict(model, X, batch_size=64):
    """Effectue des pr√©dictions par lots pour √©viter les probl√®mes de m√©moire."""
    predictions = []
    probabilities = []
    for i in range(0, len(X), batch_size):
        batch_X = X[i:i+batch_size]
        batch_predictions, batch_probabilities = predict(model, torch.tensor(batch_X, dtype=torch.float32))
        predictions.extend(batch_predictions)
        probabilities.extend(batch_probabilities)
    return predictions, probabilities

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Inference pipeline for multi-class classification")
    parser.add_argument('--hidden_size', type=int, default=32, help="Hidden layer size of the model")
    parser.add_argument('--num_classes', type=int, default=4, help="Number of output classes")
    parser.add_argument('--batch_size', type=int, default=64, help="Batch size for inference")

    args = parser.parse_args()

    # üî• Charger les donn√©es de test
    df = pd.read_csv(f"{TEST_DATA_PATH}")
    
    # V√©rifier si la colonne ID est pr√©sente
    ids = df['id'] if 'id' in df.columns else None
    df = df.drop(columns=['id'], errors='ignore')  # Supprimer la colonne ID si elle existe

    # üî• Charger le pr√©processeur
    preprocessor = joblib.load(f"{CHECKPOINT_DIR}/preprocessor.pkl")

    # ‚úÖ Aligner les colonnes avant transformation
    df_aligned = align_columns(df, preprocessor)

    # ‚úÖ Appliquer la transformation avec le pipeline d√©j√† entra√Æn√©
    X = preprocessor.pipeline.transform(df_aligned)

    # ‚úÖ Appliquer la s√©lection de features (si elle a √©t√© faite √† l'entra√Ænement)
    if preprocessor.selector:
        X = preprocessor.selector.transform(X)
    if preprocessor.selected_features_ is not None:
        X = X[:, preprocessor.selected_features_]

    # ‚úÖ V√©rification de coh√©rence avec le mod√®le
    input_size = X.shape[1]
    expected_input_size = len(preprocessor.selected_features_) if preprocessor.selected_features_ is not None else input_size

    print(f"üìå Expected input size: {expected_input_size}")
    print(f"üìå Actual input size: {input_size}")

    if input_size != expected_input_size:
        raise ValueError(
            f"‚ö†Ô∏è Erreur : X.shape[1] ({input_size}) != expected_input_size ({expected_input_size})\n"
            f"V√©rifiez que `feature_selection_method` et `k_best` sont identiques √† l'entra√Ænement."
        )
 
    print(f"‚úÖ Features align√©es avec succ√®s : {input_size} (doit √™tre identique au training)")

    # üî• Charger le mod√®le entra√Æn√©
    model = load_model(
        model_path=MODEL_PATH,
        input_size=input_size,
        hidden_size=args.hidden_size,
        num_classes=args.num_classes,
        num_layers=3,  # üî• V√©rifie le nombre de couches pour HWN
        type="mlp"  # üî• Change pour HWN si c'est le mod√®le utilis√©
    )
    # üî• Faire des pr√©dictions par lots
    predictions, probabilities = batch_predict(model, X, batch_size=args.batch_size)

    # ‚úÖ Sauvegarde des r√©sultats
    df_results = pd.DataFrame({'prediction': predictions})
    if ids is not None:
        df_results.insert(0, 'id', ids)  # Ajouter la colonne ID si disponible

    df_results.to_csv(f"{CHECKPOINT_DIR}/submission.csv", index=False)

    # ‚úÖ Affichage des r√©sultats
    print("‚úÖ Pr√©dictions r√©ussies !")
    print("üìä Aper√ßu des pr√©dictions :", df_results.head())
